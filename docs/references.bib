Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Tishby,
abstract = {Deep Neural Networks (DNNs) are analyzed via the theoretical framework of the information bottleneck (IB) principle. We first show that any DNN can be quantified by the mutual information between the layers and the input and output variables. Using this representation we can calculate the optimal information theoretic limits of the DNN and obtain finite sample generalization bounds. The advantage of getting closer to the theoretical limit is quantifiable both by the generalization bound and by the network's simplicity. We argue that both the optimal architecture, number of layers and features/connections at each layer, are related to the bifurcation points of the information bottleneck tradeoff, namely, relevant compression of the input layer with respect to the output layer. The hierarchical representations at the layered network naturally correspond to the structural phase transitions along the information curve. We believe that this new insight can lead to new optimality bounds and deep learning algorithms.},
archivePrefix = {arXiv},
arxivId = {1503.02406},
author = {Tishby, Naftali and Zaslavsky, Noga},
doi = {10.1109/ITW.2015.7133169},
eprint = {1503.02406},
file = {::},
isbn = {978-1-4799-5524-4},
journal = {Ieee},
pages = {1--5},
title = {{Deep Learning and the Information Bottleneck Principle}},
url = {https://arxiv.org/pdf/1503.02406.pdf},
year = {2015}
}
@inproceedings{Schwartz-ziv2017,
abstract = {Despite their great success, there is still no comprehensive theoretical understanding of learning with Deep Neural Networks (DNNs) or their inner organization. Previous work [Tishby and Za-slavsky (2015)] proposed to analyze DNNs in the Information Plane; i.e., the plane of the Mutual Information values that each layer preserves on the input and output variables. They suggested that the goal of the network is to optimize the Information Bottleneck (IB) tradeoff between compres-sion and prediction, successively, for each layer. In this work we follow up on this idea and demonstrate the effectiveness of the Information-Plane visualization of DNNs. Our main results are: (i) most of the training epochs in standard DL are spent on compression of the input to efficient representation and not on fitting the training labels. (ii) The representation compression phase begins when the training errors becomes small and the Stochastic Gradient Decent (SGD) epochs change from a fast drift to smaller training error into a stochastic relaxation, or random diffusion, constrained by the training error value. (iii) The converged layers lie on or very close to the Information Bottleneck (IB) theoretical bound, and the maps from the input to any hidden layer and from this hidden layer to the output satisfy the IB self-consistent equations. This generalization through noise mechanism is unique to Deep Neural Networks and absent in one layer networks. (iv) The training time is dramatically reduced when adding more hidden layers. Thus the main advantage of the hidden layers is computational. This can be explained by the reduced relaxation time, as this it scales super-linearly (exponentially for simple diffusion) with the information compression from the previous layer. (v) As we expect critical slowing down of the stochastic relaxation near phase transitions on the IB curve, we expect the hidden layers to converge to such critical points.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.00810v3},
author = {Schwartz-ziv, Ravid and Tishby, Naftali},
booktitle = {Arxiv},
eprint = {arXiv:1703.00810v3},
file = {::},
keywords = {Deep Learning,Deep Neural Networks,Information Bottleneck,Representation Learning},
pages = {1--19},
title = {{Opening the black box of Deep Neural Networks via Information}},
url = {https://arxiv.org/pdf/1703.00810.pdf},
year = {2017}
}
@article{AndrewM.SaxeYaminiBansalJoelDapelloMadhuAdvaniArtemyKolchinskyBrendanD.Tracey2017,
author = {{Andrew M. Saxe, Yamini Bansal, Joel Dapello, Madhu Advani, Artemy Kolchinsky, Brendan D. Tracey}, David C. Cox},
file = {:home/jarno/Desktop/766e53de9a687876620f7372c97175003f9b89a3.pdf:pdf},
isbn = {0444565191},
number = {November 2016},
pages = {1--15},
title = {{On the Information Bottleneck Theory of Deep Learning}},
year = {2017}
}
